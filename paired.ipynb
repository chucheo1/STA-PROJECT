{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827210a5",
   "metadata": {},
   "source": [
    "Create a bootstrap confidence interval and a hypothesis test comparing the performance of two the models across all the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a892258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_rel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2082d195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>y_true_ffnn</th>\n",
       "      <th>iso3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202211</td>\n",
       "      <td>FJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.183897</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.409958</td>\n",
       "      <td>False</td>\n",
       "      <td>FJI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202212</td>\n",
       "      <td>FJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.267831</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.099643</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.406696</td>\n",
       "      <td>False</td>\n",
       "      <td>FJI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202211</td>\n",
       "      <td>TZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.482585</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.704086</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.545236</td>\n",
       "      <td>False</td>\n",
       "      <td>TZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202212</td>\n",
       "      <td>TZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.187792</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.638444</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.534560</td>\n",
       "      <td>False</td>\n",
       "      <td>TZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202301</td>\n",
       "      <td>TZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.539319</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.608380</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538583</td>\n",
       "      <td>True</td>\n",
       "      <td>TZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>202211</td>\n",
       "      <td>MJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.182196</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.079453</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.291874</td>\n",
       "      <td>False</td>\n",
       "      <td>MNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>202212</td>\n",
       "      <td>MJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.300321</td>\n",
       "      <td>False</td>\n",
       "      <td>MNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>202211</td>\n",
       "      <td>TD</td>\n",
       "      <td>True</td>\n",
       "      <td>0.527107</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.697625</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.335496</td>\n",
       "      <td>False</td>\n",
       "      <td>TTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>202212</td>\n",
       "      <td>TD</td>\n",
       "      <td>True</td>\n",
       "      <td>0.555677</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729246</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>False</td>\n",
       "      <td>TTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>202301</td>\n",
       "      <td>TD</td>\n",
       "      <td>True</td>\n",
       "      <td>0.565700</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.591722</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.332455</td>\n",
       "      <td>True</td>\n",
       "      <td>TTO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "0       202211   FJ               False                  0.183897   \n",
       "1       202212   FJ               False                  0.267831   \n",
       "2       202211   TZ               False                  0.482585   \n",
       "3       202212   TZ               False                  0.187792   \n",
       "4       202301   TZ                True                  0.539319   \n",
       "..         ...  ...                 ...                       ...   \n",
       "359     202211   MJ               False                  0.182196   \n",
       "360     202212   MJ               False                  0.203236   \n",
       "361     202211   TD                True                  0.527107   \n",
       "362     202212   TD                True                  0.555677   \n",
       "363     202301   TD                True                  0.565700   \n",
       "\n",
       "     y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "0                 False           False              0.066500           False   \n",
       "1                 False           False              0.099643           False   \n",
       "2                 False            True              0.704086            True   \n",
       "3                 False            True              0.638444            True   \n",
       "4                  True            True              0.608380           False   \n",
       "..                  ...             ...                   ...             ...   \n",
       "359               False           False              0.079453           False   \n",
       "360               False           False              0.060189           False   \n",
       "361               False            True              0.697625            True   \n",
       "362               False            True              0.729246           False   \n",
       "363                True            True              0.591722           False   \n",
       "\n",
       "     y_pred_ffnn  y_pred_proba_ffnn  y_true_ffnn iso3  \n",
       "0          False           0.409958        False  FJI  \n",
       "1          False           0.406696        False  FJI  \n",
       "2           True           0.545236        False  TZA  \n",
       "3           True           0.534560        False  TZA  \n",
       "4           True           0.538583         True  TZA  \n",
       "..           ...                ...          ...  ...  \n",
       "359        False           0.291874        False  MNE  \n",
       "360        False           0.300321        False  MNE  \n",
       "361        False           0.335496        False  TTO  \n",
       "362        False           0.324000        False  TTO  \n",
       "363        False           0.332455         True  TTO  \n",
       "\n",
       "[364 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions=pd.read_csv(\"test_predictions.csv\")\n",
    "test_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c96442",
   "metadata": {},
   "source": [
    "# H_0: two samples have the same mean\n",
    "# H_1: two samples have the different mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ac029",
   "metadata": {},
   "source": [
    "## transformer and xgboost p value and confidence interval ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d11d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### permutation shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f439d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t=test_predictions[\"y_pred_proba_transformer\"]\n",
    "df_x=test_predictions[\"y_pred_proba_xgboost\"]\n",
    "df_f=test_predictions[\"y_pred_proba_ffnn\"]\n",
    "df_tx=pd.concat([df_t,df_x],axis=0, ignore_index=True)\n",
    "df_tf=pd.concat([df_t,df_f],axis=0, ignore_index=True)\n",
    "df_fx=pd.concat([df_f,df_x],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "806c4ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034 [-0.03089756  0.02969562]\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed\n",
    "np.random.seed(109)\n",
    "\n",
    "# Calculate the observed \n",
    "observed_test_statistics = df_t.mean() - df_x.mean()\n",
    "\n",
    "\n",
    "simdata = df_tx.copy()\n",
    "\n",
    "\n",
    "sim_test_statistics = []\n",
    "\n",
    "\n",
    "for i in range(10000):\n",
    "    # Shuffle the data randomly\n",
    "    permu_df_tx = simdata.sample(frac=1).values\n",
    "\n",
    "    # Split the shuffled data into two groups\n",
    "    permu_df_t = permu_df_tx[0 : len(permu_df_tx) // 2]\n",
    "    permu_df_x = permu_df_tx[len(permu_df_tx) // 2:]\n",
    "\n",
    "    # Calculate the test statistic \n",
    "    sim_test_statistic = permu_df_t.mean() - permu_df_x.mean()\n",
    "\n",
    "    # Store the test statistic in the list\n",
    "    sim_test_statistics.append(sim_test_statistic)\n",
    "\n",
    "# Count how many times the permuted test statistics are extreme or more extreme\n",
    "num = np.sum(np.abs(sim_test_statistics) >= np.abs(observed_test_statistics))\n",
    "\n",
    "# Calculate the p-value\n",
    "p = np.round(num / 10000, 3)\n",
    "\n",
    "confidence_interval = np.percentile(sim_test_statistics, [2.5, 97.5])\n",
    "print(p,confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 另外一个方法 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f67dfc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.05222857, -0.01358091]),\n",
       " 0.001467421045216591,\n",
       " WilcoxonResult(statistic=26934.0, pvalue=0.0017683514481583043))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "\n",
    "test_predictions = pd.read_csv(\"test_predictions.csv\")\n",
    "\n",
    "# Calculate paired differences\n",
    "test_predictions['model_difference'] = test_predictions['y_pred_proba_transformer'] - test_predictions['y_pred_proba_xgboost']\n",
    "\n",
    "# Set the number of bootstrap samples\n",
    "n_bootstrap_samples = 1000\n",
    "\n",
    "# Create an array to store bootstrap sample means\n",
    "bootstrap_sample_means = np.zeros(n_bootstrap_samples)\n",
    "\n",
    "for i in range(n_bootstrap_samples):\n",
    "    # Generate a bootstrap sample of paired differences\n",
    "    bootstrap_sample = np.random.choice(test_predictions['model_difference'], len(test_predictions), replace=True)\n",
    "    \n",
    "    # Calculate the sample statistic (mean) for the bootstrap sample\n",
    "    bootstrap_sample_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval = np.percentile(bootstrap_sample_means, [2.5, 97.5])\n",
    "\n",
    "# Perform a t-test on the paired differences\n",
    "ttest_statistic, ttest_pvalue = ttest_rel(test_predictions['y_pred_proba_transformer'], test_predictions['y_pred_proba_xgboost'])\n",
    "wilcoxon_pvalue = wilcoxon(test_predictions['y_pred_proba_transformer'], test_predictions['y_pred_proba_xgboost'])\n",
    "confidence_interval, ttest_pvalue, wilcoxon_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29643cea",
   "metadata": {},
   "source": [
    "## transformer and ffnn ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a80e501c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 [-0.02152488  0.02138699]\n"
     ]
    }
   ],
   "source": [
    "observed_test_statistics = df_t.mean() - df_f.mean()\n",
    "\n",
    "# Create a copy of the original data for permutation\n",
    "simdata = df_tf.copy()\n",
    "\n",
    "# Initialize a list to store simulated test statistics\n",
    "sim_test_statistics = []\n",
    "\n",
    "# Perform 10,000 permutations\n",
    "for i in range(10000):\n",
    "    # Shuffle the data randomly\n",
    "    permu_df_tf = simdata.sample(frac=1).values\n",
    "\n",
    "    # Split the shuffled data into two groups\n",
    "    permu_df_t = permu_df_tf[0 : len(permu_df_tf) // 2]\n",
    "    permu_df_f = permu_df_tf[len(permu_df_tf) // 2:]\n",
    "\n",
    "    # Calculate the test statistic for the permuted data\n",
    "    sim_test_statistic = permu_df_t.mean() - permu_df_f.mean()\n",
    "\n",
    "    # Store the test statistic in the list\n",
    "    sim_test_statistics.append(sim_test_statistic)\n",
    "\n",
    "# Count how many times the permuted test statistics are greater than or equal to the observed statistic\n",
    "num = np.sum(np.abs(sim_test_statistics) >= np.abs(observed_test_statistics))\n",
    "\n",
    "# Calculate the p-value\n",
    "p = np.round(num / 10000, 3)\n",
    "\n",
    "confidence_interval = np.percentile(sim_test_statistics, [2.5, 97.5])\n",
    "print(p,confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d76d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01691a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.02485198, 0.05903583]),\n",
       " 8.593371129451824e-06,\n",
       " WilcoxonResult(statistic=25852.0, pvalue=0.00024713024828037854))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "test_predictions = pd.read_csv(\"test_predictions.csv\")\n",
    "\n",
    "# Calculate paired differences\n",
    "test_predictions['model_difference'] = test_predictions['y_pred_proba_transformer'] - test_predictions['y_pred_proba_ffnn']\n",
    "\n",
    "# Set the number of bootstrap samples\n",
    "n_bootstrap_samples = 1000\n",
    "\n",
    "# Create an array to store bootstrap sample means\n",
    "bootstrap_sample_means = np.zeros(n_bootstrap_samples)\n",
    "\n",
    "for i in range(n_bootstrap_samples):\n",
    "    # Generate a bootstrap sample of paired differences\n",
    "    bootstrap_sample = np.random.choice(test_predictions['model_difference'], len(test_predictions), replace=True)\n",
    "    \n",
    "    # Calculate the sample statistic (mean) for the bootstrap sample\n",
    "    bootstrap_sample_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval = np.percentile(bootstrap_sample_means, [2.5, 97.5])\n",
    "\n",
    "# Perform a t-test on the paired differences\n",
    "ttest_statistic, ttest_pvalue = ttest_rel(test_predictions['y_pred_proba_transformer'], test_predictions['y_pred_proba_ffnn'])\n",
    "wilcoxon_pvalue = wilcoxon(test_predictions['y_pred_proba_transformer'], test_predictions['y_pred_proba_ffnn'])\n",
    "confidence_interval, ttest_pvalue, wilcoxon_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d62a4",
   "metadata": {},
   "source": [
    "## ffnn and xgboost ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bda91e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 [-0.02695939  0.02665751]\n"
     ]
    }
   ],
   "source": [
    "observed_test_statistics = df_f.mean() - df_x.mean()\n",
    "\n",
    "# Create a copy of the original data for permutation\n",
    "simdata = df_fx.copy()\n",
    "\n",
    "# Initialize a list to store simulated test statistics\n",
    "sim_test_statistics = []\n",
    "\n",
    "# Perform 10,000 permutations\n",
    "for i in range(10000):\n",
    "    # Shuffle the data randomly\n",
    "    permu_df_fx = simdata.sample(frac=1).values\n",
    "\n",
    "    # Split the shuffled data into two groups\n",
    "    permu_df_f = permu_df_fx[0 : len(permu_df_fx) // 2]\n",
    "    permu_df_x = permu_df_fx[len(permu_df_fx) // 2:]\n",
    "\n",
    "    # Calculate the test statistic for the permuted data\n",
    "    sim_test_statistic = permu_df_f.mean() - permu_df_x.mean()\n",
    "\n",
    "    # Store the test statistic in the list\n",
    "    sim_test_statistics.append(sim_test_statistic)\n",
    "\n",
    "# Count how many times the permuted test statistics are greater than or equal to the observed statistic\n",
    "num = np.sum(np.abs(sim_test_statistics) >= np.abs(observed_test_statistics))\n",
    "\n",
    "# Calculate the p-value\n",
    "p = np.round(num / 10000, 3)\n",
    "\n",
    "confidence_interval = np.percentile(sim_test_statistics, [2.5, 97.5])\n",
    "print(p,confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fa50992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.05327034, 0.09534837]),\n",
       " 6.0152950535030424e-12,\n",
       " WilcoxonResult(statistic=20177.0, pvalue=8.574266149430355e-11))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "test_predictions = pd.read_csv(\"test_predictions.csv\")\n",
    "\n",
    "# Calculate paired differences\n",
    "test_predictions['model_difference'] = test_predictions['y_pred_proba_xgboost'] - test_predictions['y_pred_proba_ffnn']\n",
    "\n",
    "# Set the number of bootstrap samples\n",
    "n_bootstrap_samples = 1000\n",
    "\n",
    "# Create an array to store bootstrap sample means\n",
    "bootstrap_sample_means = np.zeros(n_bootstrap_samples)\n",
    "\n",
    "for i in range(n_bootstrap_samples):\n",
    "    # Generate a bootstrap sample of paired differences\n",
    "    bootstrap_sample = np.random.choice(test_predictions['model_difference'], len(test_predictions), replace=True)\n",
    "    \n",
    "    # Calculate the sample statistic (mean) for the bootstrap sample\n",
    "    bootstrap_sample_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval = np.percentile(bootstrap_sample_means, [2.5, 97.5])\n",
    "\n",
    "# Perform a t-test on the paired differences\n",
    "ttest_statistic, ttest_pvalue = ttest_rel(test_predictions['y_pred_proba_xgboost'], test_predictions['y_pred_proba_ffnn'])\n",
    "wilcoxon_pvalue = wilcoxon(test_predictions['y_pred_proba_xgboost'], test_predictions['y_pred_proba_ffnn'])\n",
    "confidence_interval, ttest_pvalue, wilcoxon_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d81b63",
   "metadata": {},
   "source": [
    "## extreme high evidence agiant null hypothesis ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41103d2b",
   "metadata": {},
   "source": [
    "# q10: analyses for different model pairs on some different subsets of data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fsi category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c452188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.26712025555292e-07 0.0024450270517777355\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "\n",
    "country_indicators = pd.read_csv(\"country_indicators.csv\")\n",
    "test_predictions = pd.read_csv(\"test_predictions.csv\")\n",
    "\n",
    "# country == alert and country == stable\n",
    "subset_alert = country_indicators[country_indicators['fsi_category'] == 'Alert']\n",
    "subset_stable = country_indicators[country_indicators['fsi_category'] == 'Stable']\n",
    "\n",
    "# data of country==alert and data of country== stable\n",
    "data_subset_alert = test_predictions[test_predictions['iso3'].isin(subset_alert['iso3'])]\n",
    "data_subset_stable = test_predictions[test_predictions['iso3'].isin(subset_stable['iso3'])]\n",
    "\n",
    "# ttest\n",
    "ttest_statistic, alert_ttest_pvalue = ttest_rel(data_subset_alert['y_pred_proba_transformer'], data_subset_alert['y_pred_proba_xgboost'])\n",
    "\n",
    "\n",
    "ttest_statistic, stable_ttest_pvalue = ttest_rel(data_subset_stable['y_pred_proba_transformer'], data_subset_stable['y_pred_proba_xgboost'])\n",
    "print(alert_ttest_pvalue, stable_ttest_pvalue)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
